{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e147215",
   "metadata": {},
   "source": [
    "### 00. Desenvolvimento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "881258d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import regex as re\n",
    "import queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3ff0ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Teste com um link escolhido\n",
    "URL = \"https://pt.wikipedia.org/wiki/Ryan_Gosling\"\n",
    "\n",
    "# Faz o resquest da página e pega o html\n",
    "html = urlopen(URL)\n",
    "# Extrai o html para um txt\n",
    "site = html.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef1b7c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(site, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b2069b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "infobox = soup.find_all(\"table\", class_=re.compile(\"^[iI]nfobox\"))\n",
    "\n",
    "if infobox is not None:\n",
    "    atributos = []\n",
    "    for linha in infobox:\n",
    "        x = linha.find_all('td', {'scope': \"row\"})\n",
    "        \n",
    "        for i in x:\n",
    "            atributos.append(i)\n",
    "else:\n",
    "    print(\"Sem infobox\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7aa4655",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pessoa\n"
     ]
    }
   ],
   "source": [
    "link_de_pessoas = []\n",
    "for at in atributos:\n",
    "    # Criar if's com regex para encontrar atributos de pessoas\n",
    "    # Ex: Nome completo, Nome, Data de nascimento, Nascimento, Nacionalidade, Assinatura etc.\n",
    "    if re.search(\"[nN]ome\", at.text):\n",
    "        link_de_pessoas.append(at)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d1192c",
   "metadata": {},
   "source": [
    "### 01. Código Consolidado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42478347",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import regex as re\n",
    "\n",
    "# Teste com um link escolhido\n",
    "URL = \"https://pt.wikipedia.org/wiki/Ryan_Gosling\"\n",
    "\n",
    "# Em produção, será uma lista de URLs\n",
    "# URL = [...]\n",
    "# link_de_pessoas = []\n",
    "# for url in URL:\n",
    "#   html = urlopen(url)\n",
    "#   ...\n",
    "\n",
    "html = urlopen(URL)\n",
    "site = html.read()\n",
    "soup = BeautifulSoup(site, 'html.parser')\n",
    "\n",
    "infobox = soup.find_all(\"table\", class_=re.compile(\"^[iI]nfobox\"))\n",
    "if infobox is not None:\n",
    "    atributos = []\n",
    "    for linha in infobox:\n",
    "        x = linha.find_all('td', {'scope': \"row\"})\n",
    "        for i in x:\n",
    "            atributos.append(i)\n",
    "else:\n",
    "    print(\"Sem infobox\")\n",
    "\n",
    "for at in atributos:\n",
    "    # Criar if's com regex para encontrar atributos de pessoas\n",
    "    # Ex: Nome completo, Nome, Data de nascimento, Nascimento, Nacionalidade, Assinatura etc.\n",
    "    if re.search(\"[nN]ome\", at.text):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1f72ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import regex as re\n",
    "\n",
    "# Teste com um link escolhido\n",
    "URL = \"https://pt.wikipedia.org/wiki/Ryan_Gosling\"\n",
    "\n",
    "# Em produção, será uma lista de URLs\n",
    "# URL = [...]\n",
    "# link_de_pessoas = []\n",
    "# for url in URL:\n",
    "#   html = urlopen(url)\n",
    "#   ...\n",
    "def eh_pessoa(url):\n",
    "    html = urlopen(url)\n",
    "    site = html.read()\n",
    "    soup = BeautifulSoup(site, 'html.parser')\n",
    "    \n",
    "    infobox = soup.find_all(\"table\", class_=re.compile(\"^[iI]nfobox\"))\n",
    "    if infobox is not None:\n",
    "        atributos = []\n",
    "        for linha in infobox:\n",
    "            x = linha.find_all('td', {'scope': \"row\"})\n",
    "            for i in x:\n",
    "                atributos.append(i)\n",
    "    else:\n",
    "        print(\"Sem infobox\")\n",
    "    \n",
    "    for at in atributos:\n",
    "        # Criar if's com regex para encontrar atributos de pessoas\n",
    "        # Ex: Nome completo, Nome, Data de nascimento, Nascimento, Nacionalidade, Assinatura etc.\n",
    "        if re.search(\"[nN]ome\", at.text):\n",
    "            pass"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "431fc492db61b097"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "aeb9eb95d5b969a3"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
