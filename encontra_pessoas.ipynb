{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e147215",
   "metadata": {},
   "source": [
    "### 00. Desenvolvimento"
   ]
  },
  {
   "cell_type": "code",
   "id": "881258d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-25T13:07:29.986406Z",
     "start_time": "2025-08-25T13:07:29.982147Z"
    }
   },
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import regex as re\n",
    "import queue"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "d3ff0ec4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-25T13:07:49.712382Z",
     "start_time": "2025-08-25T13:07:49.503293Z"
    }
   },
   "source": [
    "# Teste com um link escolhido\n",
    "URL = \"https://pt.wikipedia.org/\"\n",
    "\n",
    "# Faz o resquest da página e pega o html\n",
    "html = urlopen(URL)\n",
    "# Extrai o html para um txt\n",
    "site = html.read()"
   ],
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 403: Forbidden",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mHTTPError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[6], line 5\u001B[0m\n\u001B[1;32m      2\u001B[0m URL \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhttps://pt.wikipedia.org/\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;66;03m# Faz o resquest da página e pega o html\u001B[39;00m\n\u001B[0;32m----> 5\u001B[0m html \u001B[38;5;241m=\u001B[39m urlopen(URL)\n\u001B[1;32m      6\u001B[0m \u001B[38;5;66;03m# Extrai o html para um txt\u001B[39;00m\n\u001B[1;32m      7\u001B[0m site \u001B[38;5;241m=\u001B[39m html\u001B[38;5;241m.\u001B[39mread()\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.12/urllib/request.py:215\u001B[0m, in \u001B[0;36murlopen\u001B[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001B[0m\n\u001B[1;32m    213\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    214\u001B[0m     opener \u001B[38;5;241m=\u001B[39m _opener\n\u001B[0;32m--> 215\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m opener\u001B[38;5;241m.\u001B[39mopen(url, data, timeout)\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.12/urllib/request.py:521\u001B[0m, in \u001B[0;36mOpenerDirector.open\u001B[0;34m(self, fullurl, data, timeout)\u001B[0m\n\u001B[1;32m    519\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m processor \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprocess_response\u001B[38;5;241m.\u001B[39mget(protocol, []):\n\u001B[1;32m    520\u001B[0m     meth \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(processor, meth_name)\n\u001B[0;32m--> 521\u001B[0m     response \u001B[38;5;241m=\u001B[39m meth(req, response)\n\u001B[1;32m    523\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m response\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.12/urllib/request.py:630\u001B[0m, in \u001B[0;36mHTTPErrorProcessor.http_response\u001B[0;34m(self, request, response)\u001B[0m\n\u001B[1;32m    627\u001B[0m \u001B[38;5;66;03m# According to RFC 2616, \"2xx\" code indicates that the client's\u001B[39;00m\n\u001B[1;32m    628\u001B[0m \u001B[38;5;66;03m# request was successfully received, understood, and accepted.\u001B[39;00m\n\u001B[1;32m    629\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;241m200\u001B[39m \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m code \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m300\u001B[39m):\n\u001B[0;32m--> 630\u001B[0m     response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mparent\u001B[38;5;241m.\u001B[39merror(\n\u001B[1;32m    631\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mhttp\u001B[39m\u001B[38;5;124m'\u001B[39m, request, response, code, msg, hdrs)\n\u001B[1;32m    633\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m response\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.12/urllib/request.py:559\u001B[0m, in \u001B[0;36mOpenerDirector.error\u001B[0;34m(self, proto, *args)\u001B[0m\n\u001B[1;32m    557\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m http_err:\n\u001B[1;32m    558\u001B[0m     args \u001B[38;5;241m=\u001B[39m (\u001B[38;5;28mdict\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdefault\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mhttp_error_default\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;241m+\u001B[39m orig_args\n\u001B[0;32m--> 559\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_chain(\u001B[38;5;241m*\u001B[39margs)\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.12/urllib/request.py:492\u001B[0m, in \u001B[0;36mOpenerDirector._call_chain\u001B[0;34m(self, chain, kind, meth_name, *args)\u001B[0m\n\u001B[1;32m    490\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m handler \u001B[38;5;129;01min\u001B[39;00m handlers:\n\u001B[1;32m    491\u001B[0m     func \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(handler, meth_name)\n\u001B[0;32m--> 492\u001B[0m     result \u001B[38;5;241m=\u001B[39m func(\u001B[38;5;241m*\u001B[39margs)\n\u001B[1;32m    493\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m result \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    494\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.12/urllib/request.py:639\u001B[0m, in \u001B[0;36mHTTPDefaultErrorHandler.http_error_default\u001B[0;34m(self, req, fp, code, msg, hdrs)\u001B[0m\n\u001B[1;32m    638\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mhttp_error_default\u001B[39m(\u001B[38;5;28mself\u001B[39m, req, fp, code, msg, hdrs):\n\u001B[0;32m--> 639\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m HTTPError(req\u001B[38;5;241m.\u001B[39mfull_url, code, msg, hdrs, fp)\n",
      "\u001B[0;31mHTTPError\u001B[0m: HTTP Error 403: Forbidden"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef1b7c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(site, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b2069b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "infobox = soup.find_all(\"table\", class_=re.compile(\"^[iI]nfobox\"))\n",
    "\n",
    "if infobox is not None:\n",
    "    atributos = []\n",
    "    for linha in infobox:\n",
    "        x = linha.find_all('td', {'scope': \"row\"})\n",
    "        \n",
    "        for i in x:\n",
    "            atributos.append(i)\n",
    "else:\n",
    "    print(\"Sem infobox\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7aa4655",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pessoa\n"
     ]
    }
   ],
   "source": [
    "link_de_pessoas = []\n",
    "for at in atributos:\n",
    "    # Criar if's com regex para encontrar atributos de pessoas\n",
    "    # Ex: Nome completo, Nome, Data de nascimento, Nascimento, Nacionalidade, Assinatura etc.\n",
    "    if re.search(\"[nN]ome\", at.text):\n",
    "        link_de_pessoas.append(at)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d1192c",
   "metadata": {},
   "source": [
    "### 01. Código Consolidado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42478347",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import regex as re\n",
    "\n",
    "# Teste com um link escolhido\n",
    "URL = \"https://pt.wikipedia.org/wiki/Ryan_Gosling\"\n",
    "\n",
    "# Em produção, será uma lista de URLs\n",
    "# URL = [...]\n",
    "# link_de_pessoas = []\n",
    "# for url in URL:\n",
    "#   html = urlopen(url)\n",
    "#   ...\n",
    "\n",
    "html = urlopen(URL)\n",
    "site = html.read()\n",
    "soup = BeautifulSoup(site, 'html.parser')\n",
    "\n",
    "infobox = soup.find_all(\"table\", class_=re.compile(\"^[iI]nfobox\"))\n",
    "if infobox is not None:\n",
    "    atributos = []\n",
    "    for linha in infobox:\n",
    "        x = linha.find_all('td', {'scope': \"row\"})\n",
    "        for i in x:\n",
    "            atributos.append(i)\n",
    "else:\n",
    "    print(\"Sem infobox\")\n",
    "\n",
    "for at in atributos:\n",
    "    # Criar if's com regex para encontrar atributos de pessoas\n",
    "    # Ex: Nome completo, Nome, Data de nascimento, Nascimento, Nacionalidade, Assinatura etc.\n",
    "    if re.search(\"[nN]ome\", at.text):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1f72ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import regex as re\n",
    "\n",
    "# Teste com um link escolhido\n",
    "URL = \"https://pt.wikipedia.org/wiki/Ryan_Gosling\"\n",
    "\n",
    "# Em produção, será uma lista de URLs\n",
    "# URL = [...]\n",
    "# link_de_pessoas = []\n",
    "# for url in URL:\n",
    "#   html = urlopen(url)\n",
    "#   ...\n",
    "def eh_pessoa(url):\n",
    "    html = urlopen(url)\n",
    "    site = html.read()\n",
    "    soup = BeautifulSoup(site, 'html.parser')\n",
    "    \n",
    "    infobox = soup.find_all(\"table\", class_=re.compile(\"^[iI]nfobox\"))\n",
    "    if infobox is not None:\n",
    "        atributos = []\n",
    "        for linha in infobox:\n",
    "            x = linha.find_all('td', {'scope': \"row\"})\n",
    "            for i in x:\n",
    "                atributos.append(i)\n",
    "    else:\n",
    "        print(\"Sem infobox\")\n",
    "    \n",
    "    for at in atributos:\n",
    "        # Criar if's com regex para encontrar atributos de pessoas\n",
    "        # Ex: Nome completo, Nome, Data de nascimento, Nascimento, Nacionalidade, Assinatura etc.\n",
    "        if re.search(\"[nN]ome\", at.text):\n",
    "            pass"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "431fc492db61b097"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "aeb9eb95d5b969a3"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
