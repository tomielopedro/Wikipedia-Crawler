{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e147215",
   "metadata": {},
   "source": [
    "### 00. Desenvolvimento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "881258d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-25T13:07:29.986406Z",
     "start_time": "2025-08-25T13:07:29.982147Z"
    }
   },
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import regex as re\n",
    "import queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3ff0ec4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-25T13:07:49.712382Z",
     "start_time": "2025-08-25T13:07:49.503293Z"
    }
   },
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 403: Forbidden",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m URL \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://pt.wikipedia.org/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Faz o resquest da página e pega o html\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m html \u001b[38;5;241m=\u001b[39m urlopen(URL)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Extrai o html para um txt\u001b[39;00m\n\u001b[1;32m      7\u001b[0m site \u001b[38;5;241m=\u001b[39m html\u001b[38;5;241m.\u001b[39mread()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/urllib/request.py:215\u001b[0m, in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    214\u001b[0m     opener \u001b[38;5;241m=\u001b[39m _opener\n\u001b[0;32m--> 215\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m opener\u001b[38;5;241m.\u001b[39mopen(url, data, timeout)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/urllib/request.py:521\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    519\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m processor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_response\u001b[38;5;241m.\u001b[39mget(protocol, []):\n\u001b[1;32m    520\u001b[0m     meth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(processor, meth_name)\n\u001b[0;32m--> 521\u001b[0m     response \u001b[38;5;241m=\u001b[39m meth(req, response)\n\u001b[1;32m    523\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/urllib/request.py:630\u001b[0m, in \u001b[0;36mHTTPErrorProcessor.http_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;66;03m# According to RFC 2616, \"2xx\" code indicates that the client's\u001b[39;00m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;66;03m# request was successfully received, understood, and accepted.\u001b[39;00m\n\u001b[1;32m    629\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m code \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m):\n\u001b[0;32m--> 630\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparent\u001b[38;5;241m.\u001b[39merror(\n\u001b[1;32m    631\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttp\u001b[39m\u001b[38;5;124m'\u001b[39m, request, response, code, msg, hdrs)\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/urllib/request.py:559\u001b[0m, in \u001b[0;36mOpenerDirector.error\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    557\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_err:\n\u001b[1;32m    558\u001b[0m     args \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mdict\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttp_error_default\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m+\u001b[39m orig_args\n\u001b[0;32m--> 559\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_chain(\u001b[38;5;241m*\u001b[39margs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/urllib/request.py:492\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    490\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[1;32m    491\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[0;32m--> 492\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m    493\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    494\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/urllib/request.py:639\u001b[0m, in \u001b[0;36mHTTPDefaultErrorHandler.http_error_default\u001b[0;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[1;32m    638\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhttp_error_default\u001b[39m(\u001b[38;5;28mself\u001b[39m, req, fp, code, msg, hdrs):\n\u001b[0;32m--> 639\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(req\u001b[38;5;241m.\u001b[39mfull_url, code, msg, hdrs, fp)\n",
      "\u001b[0;31mHTTPError\u001b[0m: HTTP Error 403: Forbidden"
     ]
    }
   ],
   "source": [
    "# Teste com um link escolhido\n",
    "URL = \"https://pt.wikipedia.org/\"\n",
    "\n",
    "# Faz o resquest da página e pega o html\n",
    "html = urlopen(URL)\n",
    "# Extrai o html para um txt\n",
    "site = html.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef1b7c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(site, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b2069b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "infobox = soup.find_all(\"table\", class_=re.compile(\"^[iI]nfobox\"))\n",
    "\n",
    "if infobox is not None:\n",
    "    atributos = []\n",
    "    for linha in infobox:\n",
    "        x = linha.find_all('td', {'scope': \"row\"})\n",
    "        \n",
    "        for i in x:\n",
    "            atributos.append(i)\n",
    "else:\n",
    "    print(\"Sem infobox\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7aa4655",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pessoa\n"
     ]
    }
   ],
   "source": [
    "link_de_pessoas = []\n",
    "for at in atributos:\n",
    "    # Criar if's com regex para encontrar atributos de pessoas\n",
    "    # Ex: Nome completo, Nome, Data de nascimento, Nascimento, Nacionalidade, Assinatura etc.\n",
    "    if re.search(\"[nN]ome\", at.text):\n",
    "        link_de_pessoas.append(at)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d1192c",
   "metadata": {},
   "source": [
    "### 01. Código Consolidado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42478347",
   "metadata": {},
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 403: Forbidden",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mHTTPError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m      6\u001b[39m URL = \u001b[33m\"\u001b[39m\u001b[33mhttps://pt.wikipedia.org/wiki/Ryan_Gosling\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Em produção, será uma lista de URLs\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# URL = [...]\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# link_de_pessoas = []\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# for url in URL:\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m#   html = urlopen(url)\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m#   ...\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m html = \u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mURL\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m site = html.read()\n\u001b[32m     17\u001b[39m soup = BeautifulSoup(site, \u001b[33m'\u001b[39m\u001b[33mhtml.parser\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\urllib\\request.py:215\u001b[39m, in \u001b[36murlopen\u001b[39m\u001b[34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[39m\n\u001b[32m    213\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    214\u001b[39m     opener = _opener\n\u001b[32m--> \u001b[39m\u001b[32m215\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopener\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\urllib\\request.py:521\u001b[39m, in \u001b[36mOpenerDirector.open\u001b[39m\u001b[34m(self, fullurl, data, timeout)\u001b[39m\n\u001b[32m    519\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m processor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.process_response.get(protocol, []):\n\u001b[32m    520\u001b[39m     meth = \u001b[38;5;28mgetattr\u001b[39m(processor, meth_name)\n\u001b[32m--> \u001b[39m\u001b[32m521\u001b[39m     response = \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    523\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\urllib\\request.py:630\u001b[39m, in \u001b[36mHTTPErrorProcessor.http_response\u001b[39m\u001b[34m(self, request, response)\u001b[39m\n\u001b[32m    627\u001b[39m \u001b[38;5;66;03m# According to RFC 2616, \"2xx\" code indicates that the client's\u001b[39;00m\n\u001b[32m    628\u001b[39m \u001b[38;5;66;03m# request was successfully received, understood, and accepted.\u001b[39;00m\n\u001b[32m    629\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[32m200\u001b[39m <= code < \u001b[32m300\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m630\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparent\u001b[49m\u001b[43m.\u001b[49m\u001b[43merror\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    631\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mhttp\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhdrs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    633\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\urllib\\request.py:559\u001b[39m, in \u001b[36mOpenerDirector.error\u001b[39m\u001b[34m(self, proto, *args)\u001b[39m\n\u001b[32m    557\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m http_err:\n\u001b[32m    558\u001b[39m     args = (\u001b[38;5;28mdict\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mdefault\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mhttp_error_default\u001b[39m\u001b[33m'\u001b[39m) + orig_args\n\u001b[32m--> \u001b[39m\u001b[32m559\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\urllib\\request.py:492\u001b[39m, in \u001b[36mOpenerDirector._call_chain\u001b[39m\u001b[34m(self, chain, kind, meth_name, *args)\u001b[39m\n\u001b[32m    490\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[32m    491\u001b[39m     func = \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[32m--> \u001b[39m\u001b[32m492\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    493\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    494\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\urllib\\request.py:639\u001b[39m, in \u001b[36mHTTPDefaultErrorHandler.http_error_default\u001b[39m\u001b[34m(self, req, fp, code, msg, hdrs)\u001b[39m\n\u001b[32m    638\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mhttp_error_default\u001b[39m(\u001b[38;5;28mself\u001b[39m, req, fp, code, msg, hdrs):\n\u001b[32m--> \u001b[39m\u001b[32m639\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(req.full_url, code, msg, hdrs, fp)\n",
      "\u001b[31mHTTPError\u001b[39m: HTTP Error 403: Forbidden"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import regex as re\n",
    "\n",
    "# Teste com um link escolhido\n",
    "URL = \"https://pt.wikipedia.org/wiki/Ryan_Gosling\"\n",
    "\n",
    "# Em produção, será uma lista de URLs\n",
    "# URL = [...]\n",
    "# link_de_pessoas = []\n",
    "# for url in URL:\n",
    "#   html = urlopen(url)\n",
    "#   ...\n",
    "\n",
    "html = urlopen(URL)\n",
    "site = html.read()\n",
    "soup = BeautifulSoup(site, 'html.parser')\n",
    "\n",
    "infobox = soup.find_all(\"table\", class_=re.compile(\"^[iI]nfobox\"))\n",
    "if infobox is not None:\n",
    "    atributos = []\n",
    "    for linha in infobox:\n",
    "        x = linha.find_all('td', {'scope': \"row\"})\n",
    "        for i in x:\n",
    "            atributos.append(i)\n",
    "else:\n",
    "    print(\"Sem infobox\")\n",
    "\n",
    "for at in atributos:\n",
    "    # Criar if's com regex para encontrar atributos de pessoas\n",
    "    # Ex: Nome completo, Nome, Data de nascimento, Nascimento, Nacionalidade, Assinatura etc.\n",
    "    if re.search(\"[nN]ome\", at.text):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1f72ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import regex as re\n",
    "\n",
    "# Teste com um link escolhido\n",
    "URL = \"https://pt.wikipedia.org/wiki/Ryan_Gosling\"\n",
    "\n",
    "# Em produção, será uma lista de URLs\n",
    "# URL = [...]\n",
    "# link_de_pessoas = []\n",
    "# for url in URL:\n",
    "#   html = urlopen(url)\n",
    "#   ...\n",
    "\n",
    "\n",
    "\n",
    "def eh_pessoa(url):\n",
    "    html = urlopen(url)\n",
    "    site = html.read()\n",
    "    soup = BeautifulSoup(site, 'html.parser')\n",
    "    \n",
    "    infobox = soup.find_all(\"table\", class_=re.compile(\"^[iI]nfobox\"))\n",
    "    if infobox is not None:\n",
    "        atributos = []\n",
    "        for linha in infobox:\n",
    "            x = linha.find_all('td', {'scope': \"row\"})\n",
    "            for i in x:\n",
    "                atributos.append(i)\n",
    "    else:\n",
    "        print(\"Sem infobox\")\n",
    "    \n",
    "    for at in atributos:\n",
    "        # Criar if's com regex para encontrar atributos de pessoas\n",
    "        # Ex: Nome completo, Nome, Data de nascimento, Nascimento, Nacionalidade, Assinatura etc.\n",
    "        if re.search(\"[nN]ome\", at.text):\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "431fc492db61b097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nome completo\n",
      "\n",
      "Nascimento\n",
      "\n",
      "Nacionalidade\n",
      "\n",
      "Ocupação\n",
      "\n",
      "Atividade\n",
      "\n",
      "Cônjuge\n",
      "\n",
      "Filho(a)(s)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from urllib.request import urlopen, Request\n",
    "from bs4 import BeautifulSoup\n",
    "import regex as re\n",
    "\n",
    "# Teste com um link escolhido\n",
    "URL = \"https://pt.wikipedia.org/wiki/Ryan_Gosling\"\n",
    "\n",
    "def eh_pessoa(url):\n",
    "\n",
    "    headers = {\n",
    "        \"User-Agent\": (\n",
    "            \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) \"\n",
    "            \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "            \"Chrome/115.0 Safari/537.36\"\n",
    "        )\n",
    "    }\n",
    "\n",
    "    req = Request(url, headers=headers)   # define o User-Agent\n",
    "    \n",
    "    \"\"\"Verifica se a URL corresponde a uma pessoa\"\"\"\n",
    "    html = urlopen(req)\n",
    "    site = html.read()\n",
    "\n",
    "    soup = BeautifulSoup(site, 'html.parser')\n",
    "\n",
    "    infobox = soup.find(\"table\", class_=re.compile(\"^[iI]nfobox\"))\n",
    "    if not infobox:\n",
    "        return False\n",
    "\n",
    "    atributos = infobox.find_all('td', {'scope': \"row\"})\n",
    "    prob = 0\n",
    "    for at in atributos:\n",
    "        print(at.text)\n",
    "        if re.search(\"[Nn]ome\", at.text):\n",
    "            prob += 1\n",
    "        if re.search(\"[Nn]ascimento|[Dd]ata de [Nn]ascimento|[Mm]orte\", at.text): \n",
    "            prob += 1\n",
    "        if re.search(\"[Nn]acionalidade|[Cc]idadania\", at.text): \n",
    "            prob += 1\n",
    "        if re.search(\"[Aa]ssinatura\", at.text): \n",
    "            prob += 1\n",
    "        if re.search(\"[Pp]rofissão|[Oo]cupação\", at.text):  \n",
    "            prob += 1\n",
    "        if re.search(\"[Ee]sposa|[Cc]ônjugue\", at.text):\n",
    "            prob += 1\n",
    "\n",
    "    # prob_ajustada = (prob - 0) / (6 - 0)\n",
    "    prob_ajustada = prob / 5\n",
    "    # prob_ajustada = prob\n",
    "\n",
    "    return prob_ajustada\n",
    "\n",
    "eh_pessoa(URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb9eb95d5b969a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
